{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b52bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Run 1/72: K=100, rho=0.01, eps=0.5, method=SRR, active=None ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# --- Config and States ---\n",
    "\n",
    "@dataclass\n",
    "class RandOpts:\n",
    "    method: str\n",
    "    eps1_coeff: List[float]\n",
    "    dirichlet_coeff: float\n",
    "\n",
    "@dataclass\n",
    "class OnEstOpts:\n",
    "    on_est_vec: List[int]\n",
    "    active_on_est_method: int\n",
    "    online_EM_step_size_param: float\n",
    "    offline_EM_iters: int\n",
    "    offline_EM_update_per: int\n",
    "    P_quad_prog_update_per: int\n",
    "\n",
    "@dataclass\n",
    "class FinEstOpts:\n",
    "    fin_est_vec: List[int]\n",
    "    offline_EM_iters: int\n",
    "    online_EM_step_size_param: float\n",
    "    online_EM_iters: int\n",
    "\n",
    "@dataclass\n",
    "class SimulationState:\n",
    "    # Core data arrays\n",
    "    Y: np.ndarray\n",
    "    log_P_yx: np.ndarray\n",
    "    Theta_Est: List[np.ndarray]\n",
    "    \n",
    "    # State for specific estimators\n",
    "    C: Optional[np.ndarray] = None\n",
    "    theta_online_EM_est: Optional[np.ndarray] = None\n",
    "    theta_offline_est: Optional[np.ndarray] = None\n",
    "    theta_QP1_est: Optional[np.ndarray] = None\n",
    "    theta_QP2_est: Optional[np.ndarray] = None\n",
    "    \n",
    "    # QP Accumulators\n",
    "    Sum_GHTGH: Optional[np.ndarray] = None\n",
    "    sum_GHTc: Optional[np.ndarray] = None\n",
    "    Sum_HTGH: Optional[np.ndarray] = None\n",
    "    sum_HTc: Optional[np.ndarray] = None\n",
    "    \n",
    "    # Estimation State\n",
    "    theta_tilde: Optional[np.ndarray] = None\n",
    "\n",
    "# --- Utilities ---\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_x = np.max(x, axis=0)\n",
    "    return np.log(np.sum(np.exp(x - max_x), axis=0)) + max_x\n",
    "\n",
    "def calculate_utility(theta, G, util_type):\n",
    "    theta_ord = np.sort(theta)[::-1]\n",
    "    if util_type == 6: # Prob(Y = X)\n",
    "        return np.sum(theta_ord * np.diag(G))\n",
    "    return 0\n",
    "\n",
    "def make_G(K, k0, eps1, eps2):\n",
    "    exp_eps1, exp_eps2 = np.exp(eps1), np.exp(eps2)\n",
    "    p11 = exp_eps1 / (exp_eps1 + min(k0, K - 1))\n",
    "    p12 = 1 / (exp_eps1 + min(k0, K - 1))\n",
    "    if K - k0 - 1 <= 0 or (exp_eps2 + K - k0 - 1) == 0:\n",
    "        p22, p21 = 1, 0\n",
    "    else:\n",
    "        p22 = exp_eps2 / (exp_eps2 + K - k0 - 1)\n",
    "        p21 = 1 / (exp_eps2 + K - k0 - 1)\n",
    "    G = np.zeros((K, K))\n",
    "    if k0 > 0: G[0:k0, 0:k0] = (p11 - p12) * np.eye(k0) + p12\n",
    "    if K > k0:\n",
    "        G[k0:K, k0:K] = p11 * ((p22 - p21) * np.eye(K-k0) + p21)\n",
    "        G[k0:K, 0:k0] = p12 / (K - k0) if K > k0 else 0\n",
    "        G[0:k0, k0:K] = p12\n",
    "    return G\n",
    "\n",
    "# --- Estimation Algorithms ---\n",
    "\n",
    "def MLE_RR(Y, K, eps_DP):\n",
    "    S, _ = np.histogram(Y, bins=np.arange(1, K + 2))\n",
    "    S_sorted = np.sort(S)\n",
    "    k = 0\n",
    "    while k < K:\n",
    "        denominator = S_sorted[k]\n",
    "        if denominator == 0: break\n",
    "        if (K - k) + np.exp(eps_DP) - 1 - np.sum(S_sorted[k:]) / denominator < 0:\n",
    "            k += 1\n",
    "        else: break\n",
    "    sum_S_sorted_k_onward = np.sum(S_sorted[k:])\n",
    "    if sum_S_sorted_k_onward == 0: return np.ones(K) / K\n",
    "    Phi_vec = S / sum_S_sorted_k_onward\n",
    "    term1 = (K - k) / (np.exp(eps_DP) - 1) + 1\n",
    "    term2 = 1 / (np.exp(eps_DP) - 1)\n",
    "    theta = np.maximum(0, Phi_vec * term1 - term2)\n",
    "    return theta / np.sum(theta) if np.sum(theta) > 0 else np.ones(K) / K\n",
    "\n",
    "def offline_LDP_EM(theta0, log_P_yx, M):\n",
    "    theta_est = theta0.flatten().copy()\n",
    "    K = len(theta_est)\n",
    "    Theta_est = np.zeros((M, K))\n",
    "    for m in range(M):\n",
    "        log_Pi_post = log_P_yx + np.log(theta_est[:, np.newaxis])\n",
    "        Pi_post = np.exp(log_Pi_post - log_sum_exp(log_Pi_post))\n",
    "        theta_est = np.mean(Pi_post, axis=1)\n",
    "        Theta_est[m, :] = theta_est\n",
    "    return Theta_est\n",
    "\n",
    "def estimate_online_em(current_theta, p_yx_vec, t, step_size_param):\n",
    "    pi_post_unnorm = np.log(current_theta) + np.log(p_yx_vec)\n",
    "    pi_post = np.exp(pi_post_unnorm - log_sum_exp(pi_post_unnorm))\n",
    "    gamma_t = (t + 1) ** (-step_size_param)\n",
    "    return (1 - gamma_t) * current_theta + gamma_t * pi_post\n",
    "\n",
    "def estimate_online_mm(C, H, y, t, K, K_prime, eps_DP):\n",
    "    C[H == y] += 1\n",
    "    p = np.exp(eps_DP) / (np.exp(eps_DP) + K_prime - 1)\n",
    "    q = 1 / K_prime\n",
    "    F = (C - (t + 1) * q) / (p - q)\n",
    "    F_max = np.maximum(F, 0)\n",
    "    return F_max / np.sum(F_max) if np.sum(F_max) > 0 else np.ones(K)/K\n",
    "\n",
    "def estimate_online_qp1(current_theta, Sum_GHTGH, sum_GHTc):\n",
    "    def quad_fun(theta): return 0.5 * theta.T @ Sum_GHTGH @ theta - sum_GHTc @ theta\n",
    "    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1}, {'type': 'ineq', 'fun': lambda x: x})\n",
    "    res = minimize(quad_fun, current_theta, method='SLSQP', constraints=cons, options={'disp': False})\n",
    "    return res.x\n",
    "\n",
    "def estimate_online_qp2(current_theta, Sum_HTGH, sum_HTc):\n",
    "    MM2 = Sum_HTGH.T @ Sum_HTGH\n",
    "    vv2 = -Sum_HTGH.T @ sum_HTc\n",
    "    def quad_fun(theta): return 0.5 * theta.T @ MM2 @ theta + vv2 @ theta\n",
    "    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1}, {'type': 'ineq', 'fun': lambda x: x})\n",
    "    res = minimize(quad_fun, current_theta, method='SLSQP', constraints=cons, options={'disp': False})\n",
    "    return res.x\n",
    "\n",
    "def estimate_final_online_em(log_P_yx, initial_theta, T, iters, step_size_param):\n",
    "    start_time = time.time()\n",
    "    theta_est = initial_theta.copy()\n",
    "    theta_est_all = np.zeros((iters, len(initial_theta)))\n",
    "    for i in range(iters):\n",
    "        for t_inner in range(T):\n",
    "            theta_est = estimate_online_em(theta_est, np.exp(log_P_yx[:, t_inner]), i * T + t_inner, step_size_param)\n",
    "        theta_est_all[i, :] = theta_est\n",
    "    return theta_est_all, time.time() - start_time\n",
    "\n",
    "def estimate_final_mm(C, T, K, K_prime, eps_DP):\n",
    "    p = np.exp(eps_DP) / (np.exp(eps_DP) + K_prime - 1)\n",
    "    q = 1 / K_prime\n",
    "    F = (C - T * q) / (p - q)\n",
    "    F_max = np.maximum(F, 0)\n",
    "    return F_max / np.sum(F_max) if np.sum(F_max) > 0 else np.ones(K)/K, 0.0\n",
    "\n",
    "# --- Components ---\n",
    "\n",
    "def initialize_state(K, T, theta0, on_est_opts, fin_est_opts):\n",
    "    use_qp = np.sum(fin_est_opts.fin_est_vec[4:6]) + np.sum(on_est_opts.on_est_vec[4:6]) > 0\n",
    "    return SimulationState(\n",
    "        Y=np.zeros(T), log_P_yx=np.zeros((K, T)), Theta_Est=[np.zeros((K, T)) for _ in range(6)],\n",
    "        C=np.zeros(K) if on_est_opts.on_est_vec[3] or fin_est_opts.fin_est_vec[3] else None,\n",
    "        theta_online_EM_est=theta0.copy() if on_est_opts.on_est_vec[1] else None,\n",
    "        theta_offline_est=theta0.copy() if on_est_opts.on_est_vec[2] else None,\n",
    "        theta_QP1_est=theta0.copy() if on_est_opts.on_est_vec[4] else None,\n",
    "        theta_QP2_est=theta0.copy() if on_est_opts.on_est_vec[5] else None,\n",
    "        Sum_GHTGH=np.zeros((K, K)) if use_qp else None, sum_GHTc=np.zeros(K) if use_qp else None,\n",
    "        Sum_HTGH=np.zeros((K, K)) if use_qp else None, sum_HTc=np.zeros(K) if use_qp else None,\n",
    "        theta_tilde=theta0.copy()\n",
    "    )\n",
    "\n",
    "def initialize_adaptive_mechanisms(K_prime, eps_DP, rand_opts):\n",
    "    GG = []\n",
    "    for eps1_coeff in rand_opts.eps1_coeff:\n",
    "        eps1 = eps1_coeff * eps_DP\n",
    "        Sc_min = int(np.ceil(np.exp(eps_DP - eps1)))\n",
    "        k_vec = np.arange(Sc_min, K_prime + 1)\n",
    "        eps2_UB = np.full(K_prime + 1, eps_DP)\n",
    "        denom = np.exp(eps1 - eps_DP) * k_vec - 1\n",
    "        valid_k_vec = k_vec[denom != 0]\n",
    "        eps2_UB[valid_k_vec] = (valid_k_vec - 1) / denom[denom != 0]\n",
    "        eps2_vec = np.minimum(eps_DP, eps2_UB)\n",
    "        for k in range(1, K_prime + 1): GG.append(make_G(K_prime, k, eps1, eps2_vec[k]))\n",
    "    return GG\n",
    "\n",
    "def perform_privatization(t, x, T, state, G0, GG, K, K_prime, rand_opts, hashing):\n",
    "    H_mtx = np.eye(K_prime, dtype=int)[np.random.randint(0, K_prime, size=K)].T if hashing else None\n",
    "    H = np.arange(K) if not hashing else np.where(H_mtx.T)[1]\n",
    "    if rand_opts.method not in ['RRRR', 'OLH+RRRR'] or t < T // 10:\n",
    "        G_current = G0\n",
    "    else:\n",
    "        theta_tilde_compressed = H_mtx @ state.theta_tilde if hashing else state.theta_tilde\n",
    "        ord_ind = np.argsort(theta_tilde_compressed)[::-1]\n",
    "        L = [calculate_utility(theta_tilde_compressed[ord_ind], g, 6) for g in GG]\n",
    "        k_best = np.argmax(L)\n",
    "        ord_ind_inv = np.argsort(ord_ind)\n",
    "        G_current = GG[k_best][ord_ind_inv, :][:, ord_ind_inv]\n",
    "    y = np.random.choice(K_prime, p=G_current[:, H[x]])\n",
    "    p_yx_vec = G_current[y, H]\n",
    "    return y, p_yx_vec, H, G_current, H_mtx\n",
    "\n",
    "def update_online_estimates(t, y, p_yx_vec, H, G_current, H_mtx, state, K, K_prime, eps_DP, on_est_opts, hashing):\n",
    "    if on_est_opts.on_est_vec[0]: state.Theta_Est[0][:, t] = MLE_RR(state.Y[:t+1], K, eps_DP)\n",
    "    if on_est_opts.on_est_vec[1]:\n",
    "        state.theta_online_EM_est = estimate_online_em(state.theta_online_EM_est, p_yx_vec, t, on_est_opts.online_EM_step_size_param)\n",
    "        state.Theta_Est[1][:, t] = state.theta_online_EM_est\n",
    "    if on_est_opts.on_est_vec[2]:\n",
    "        if (t + 1) % on_est_opts.offline_EM_update_per == 0:\n",
    "            state.theta_offline_est = offline_LDP_EM(state.theta_offline_est, state.log_P_yx[:, :t+1], on_est_opts.offline_EM_iters)[-1,:]\n",
    "        state.Theta_Est[2][:, t] = state.theta_offline_est\n",
    "    if on_est_opts.on_est_vec[3]: state.Theta_Est[3][:, t] = estimate_online_mm(state.C, H, y, t, K, K_prime, eps_DP)\n",
    "    if state.Sum_GHTGH is not None:\n",
    "        GH_curr = G_current @ H_mtx if hashing else G_current\n",
    "        ct = np.eye(K_prime)[y]\n",
    "        state.Sum_GHTGH += GH_curr.T @ GH_curr; state.sum_GHTc += GH_curr.T @ ct\n",
    "        state.Sum_HTGH += H_mtx.T @ GH_curr if hashing else GH_curr; state.sum_HTc += H_mtx.T @ ct if hashing else ct\n",
    "    if on_est_opts.on_est_vec[4]:\n",
    "        if (t + 1) % on_est_opts.P_quad_prog_update_per == 0:\n",
    "            state.theta_QP1_est = estimate_online_qp1(state.theta_QP1_est, state.Sum_GHTGH, state.sum_GHTc)\n",
    "        state.Theta_Est[4][:, t] = state.theta_QP1_est\n",
    "    if on_est_opts.on_est_vec[5]:\n",
    "        if (t + 1) % on_est_opts.P_quad_prog_update_per == 0:\n",
    "            state.theta_QP2_est = estimate_online_qp2(state.theta_QP2_est, state.Sum_HTGH, state.sum_HTc)\n",
    "        state.Theta_Est[5][:, t] = state.theta_QP2_est\n",
    "\n",
    "def adapt_mechanism(t, state, rand_opts, on_est_opts):\n",
    "    theta_est_to_be_used = state.Theta_Est[on_est_opts.active_on_est_method - 1][:, t]\n",
    "    gamma_shape = 1 + rand_opts.dirichlet_coeff * (t + 1) * theta_est_to_be_used\n",
    "    gamma_shape[gamma_shape < 0] = 0\n",
    "    state.theta_tilde = np.random.gamma(gamma_shape)\n",
    "    state.theta_tilde /= np.sum(state.theta_tilde)\n",
    "\n",
    "def run_final_estimation(state, K, K_prime, eps_DP, theta0, fin_est_opts, on_est_opts):\n",
    "    theta_fin_est = [np.zeros(K) for _ in range(6)]\n",
    "    comp_times = np.zeros(6)\n",
    "    initial_theta_for_final = state.Theta_Est[on_est_opts.active_on_est_method - 1][:, -1] if on_est_opts.active_on_est_method > 0 else theta0\n",
    "\n",
    "    if fin_est_opts.fin_est_vec[0]:\n",
    "        start = time.time(); theta_fin_est[0] = MLE_RR(state.Y, K, eps_DP); comp_times[0] = time.time() - start\n",
    "    if fin_est_opts.fin_est_vec[1]:\n",
    "        theta_fin_est[1], comp_times[1] = estimate_final_online_em(state.log_P_yx, initial_theta_for_final, len(state.Y), fin_est_opts.online_EM_iters, fin_est_opts.online_EM_step_size_param)\n",
    "    if fin_est_opts.fin_est_vec[2]:\n",
    "        start = time.time(); theta_fin_est[2] = offline_LDP_EM(initial_theta_for_final, state.log_P_yx, fin_est_opts.offline_EM_iters); comp_times[2] = time.time() - start\n",
    "    if fin_est_opts.fin_est_vec[3]:\n",
    "        theta_fin_est[3], comp_times[3] = estimate_final_mm(state.C, len(state.Y), K, K_prime, eps_DP)\n",
    "    if fin_est_opts.fin_est_vec[4]:\n",
    "        start = time.time(); theta_fin_est[4] = estimate_online_qp1(theta0, state.Sum_GHTGH, state.sum_GHTc); comp_times[4] = time.time() - start\n",
    "    if fin_est_opts.fin_est_vec[5]:\n",
    "        start = time.time(); theta_fin_est[5] = estimate_online_qp2(theta0, state.Sum_HTGH, state.sum_HTc); comp_times[5] = time.time() - start\n",
    "        \n",
    "    return theta_fin_est, comp_times\n",
    "\n",
    "# --- Runner ---\n",
    "\n",
    "def Adaptive_LDP(X, K, K_prime, eps_DP, rand_opts: RandOpts, on_est_opts: OnEstOpts, fin_est_opts: FinEstOpts, theta0):\n",
    "    T = len(X)\n",
    "    hashing = 1 if rand_opts.method in ['OLH', 'OLH+RRRR'] else 0\n",
    "    if not hashing: K_prime = K\n",
    "    \n",
    "    state = initialize_state(K, T, theta0, on_est_opts, fin_est_opts)\n",
    "    G0 = np.full((K_prime, K_prime), 1 / (np.exp(eps_DP) + K_prime - 1))\n",
    "    np.fill_diagonal(G0, np.exp(eps_DP) / (np.exp(eps_DP) + K_prime - 1))\n",
    "    GG = initialize_adaptive_mechanisms(K_prime, eps_DP, rand_opts) if rand_opts.method in ['RRRR', 'OLH+RRRR'] else []\n",
    "\n",
    "    for t in range(T):\n",
    "        y, p_yx_vec, H, G_current, H_mtx = perform_privatization(t, X[t] - 1, T, state, G0, GG, K, K_prime, rand_opts, hashing)\n",
    "        state.Y[t] = y + 1\n",
    "        state.log_P_yx[:, t] = np.log(p_yx_vec)\n",
    "        update_online_estimates(t, y, p_yx_vec, H, G_current, H_mtx, state, K, K_prime, eps_DP, on_est_opts, hashing)\n",
    "        if rand_opts.method in ['RRRR', 'OLH+RRRR'] and on_est_opts.active_on_est_method > 0:\n",
    "            adapt_mechanism(t, state, rand_opts, on_est_opts)\n",
    "\n",
    "    theta_fin_est, comp_times = run_final_estimation(state, K, K_prime, eps_DP, theta0, fin_est_opts, on_est_opts)\n",
    "    return {\"Theta_Online_Est\": state.Theta_Est, \"Theta_Fin_Est\": theta_fin_est, \"offline_est_comp_times\": comp_times}\n",
    "\n",
    "# --- Experiment ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Experiment Configuration\n",
    "    eps_DP_vec = [0.5, 1, 2]; K_vec = [100]; rho_coeff_vec = [0.01, 0.05, 0.5]; MC_run = 10\n",
    "    Online_est_methods = ['Exact MLE-on', 'online EM-on', 'offline EM-on', 'Simple MM-on', 'Quad Prog1-on', 'Quad Prog2-on']\n",
    "    Offline_est_methods = ['Exact MLE-off', 'online EM-off', 'offline EM-off', 'Simple MM-off', 'Quad Prog1-off', 'Quad Prog2-off']\n",
    "    method_params_cell = [\n",
    "        {'rand_method': 'SRR', 'on_est_vec': [1, 0, 0, 1, 1, 0], 'fin_est_vec': [1, 0, 1, 1, 1, 1], 'active_on_est_method': 0},\n",
    "        {'rand_method': 'OLH', 'on_est_vec': [0, 1, 0, 1, 1, 1], 'fin_est_vec': [0, 1, 1, 1, 1, 1], 'active_on_est_method': 0},\n",
    "        {'rand_method': 'RRRR', 'on_est_vec': [0, 1, 0, 0, 0, 0], 'fin_est_vec': [0, 1, 1, 0, 1, 1], 'active_on_est_method': 2},\n",
    "        {'rand_method': 'RRRR', 'on_est_vec': [0, 0, 0, 0, 1, 0], 'fin_est_vec': [0, 1, 1, 0, 1, 1], 'active_on_est_method': 5},\n",
    "        {'rand_method': 'RRRR', 'on_est_vec': [0, 0, 0, 0, 0, 1], 'fin_est_vec': [0, 1, 1, 0, 1, 1], 'active_on_est_method': 6},\n",
    "        {'rand_method': 'OLH+RRRR', 'on_est_vec': [0, 1, 0, 0, 0, 0], 'fin_est_vec': [0, 1, 1, 0, 1, 1], 'active_on_est_method': 2},\n",
    "        {'rand_method': 'OLH+RRRR', 'on_est_vec': [0, 0, 0, 0, 1, 0], 'fin_est_vec': [0, 1, 1, 0, 1, 1], 'active_on_est_method': 5},\n",
    "        {'rand_method': 'OLH+RRRR', 'on_est_vec': [0, 0, 0, 0, 0, 1], 'fin_est_vec': [0, 1, 1, 0, 1, 1], 'active_on_est_method': 6}\n",
    "    ]\n",
    "    \n",
    "    results_list = []\n",
    "    total_runs = len(K_vec) * len(rho_coeff_vec) * len(eps_DP_vec) * len(method_params_cell)\n",
    "    run_count = 0\n",
    "\n",
    "    for K in K_vec:\n",
    "        for rho_coeff in rho_coeff_vec:\n",
    "            for eps_DP in eps_DP_vec:\n",
    "                for params in method_params_cell:\n",
    "                    run_count += 1\n",
    "                    active_method_str = 'None' if params['active_on_est_method'] == 0 else Online_est_methods[params['active_on_est_method']-1]\n",
    "                    print(f\"\\n--- Run {run_count}/{total_runs}: K={K}, rho={rho_coeff}, eps={eps_DP}, method={params['rand_method']}, active={active_method_str} ---\")\n",
    "                    \n",
    "                    mc_results = []\n",
    "                    for mc in range(MC_run):\n",
    "                        T = 100 * K; theta0 = np.ones(K) / K\n",
    "                        theta_true = np.random.gamma(rho_coeff * np.ones(K), 1); theta_true /= np.sum(theta_true)\n",
    "                        X = np.random.choice(np.arange(1, K + 1), size=T, p=theta_true)\n",
    "                        K_prime = int(np.ceil(np.exp(eps_DP) + 1))\n",
    "                        rand_opts = RandOpts(params['rand_method'], [0.8, 0.9, 1], 0.01)\n",
    "                        on_est_opts = OnEstOpts(params['on_est_vec'], params['active_on_est_method'], 0.55, 100, 100, 100)\n",
    "                        fin_est_opts = FinEstOpts(params['fin_est_vec'], 1000, 0.55, 100)\n",
    "                        outputs = Adaptive_LDP(X, K, K_prime, eps_DP, rand_opts, on_est_opts, fin_est_opts, theta0)\n",
    "                        \n",
    "                        res = {'mc': mc, 'K': K, 'rho': rho_coeff, 'eps_DP': eps_DP, 'rand_method': params['rand_method'], 'active_method': active_method_str}\n",
    "                        for i, name in enumerate(Online_est_methods):\n",
    "                            if on_est_opts.on_est_vec[i]: res[f'TV_{name}'] = 0.5 * np.sum(np.abs(outputs['Theta_Online_Est'][i][:, -1] - theta_true))\n",
    "                        for i, name in enumerate(Offline_est_methods):\n",
    "                            if fin_est_opts.fin_est_vec[i]:\n",
    "                                est = outputs['Theta_Fin_Est'][i]\n",
    "                                final_est = est[-1, :] if est.ndim > 1 else est\n",
    "                                res[f'TV_{name}'] = 0.5 * np.sum(np.abs(final_est - theta_true))\n",
    "                        mc_results.append(res)\n",
    "\n",
    "                    temp_df = pd.DataFrame(mc_results)\n",
    "                    tv_cols = [col for col in temp_df.columns if 'TV_' in col]\n",
    "                    mean_tvs = temp_df[tv_cols].mean()\n",
    "                    \n",
    "                    print(\"    Average TV Distances for this run:\")\n",
    "                    for col, val in mean_tvs.items():\n",
    "                        print(f\"      {col:<22}: {val:.4f}\")\n",
    "                    results_list.extend(mc_results)\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    grouping_cols = ['K', 'rho', 'eps_DP', 'rand_method', 'active_method']\n",
    "    mean_results = results_df.groupby(grouping_cols).mean().drop('mc', axis=1)\n",
    "    \n",
    "    print(\"\\n\\n--- FINAL AGGREGATE RESULTS (MEAN TV) ---\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 200):\n",
    "        print(mean_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
